{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11424983,"sourceType":"datasetVersion","datasetId":7155358},{"sourceId":11425142,"sourceType":"datasetVersion","datasetId":7155490},{"sourceId":11502227,"sourceType":"datasetVersion","datasetId":7211282}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\n# -----------------------------\n# 1. Model Definitions\n# -----------------------------\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(Down, self).__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(Up, self).__init__()\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass AttentionBlock(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super(AttentionBlock, self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1),\n            nn.BatchNorm2d(F_int)\n        )\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1),\n            nn.BatchNorm2d(F_int)\n        )\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        if g.shape[2:] != x.shape[2:]:\n            g = F.interpolate(g, size=x.shape[2:], mode='bilinear', align_corners=True)\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        return x * psi\n\nclass ProtoUNet(nn.Module):\n    def __init__(self, n_channels=3, n_classes=1, num_prototypes=5):\n        super(ProtoUNet, self).__init__()\n        self.num_prototypes = num_prototypes\n        self.features = [64, 128, 256, 512]\n        # Encoder\n        self.inc = DoubleConv(n_channels, self.features[0])\n        self.down1 = Down(self.features[0], self.features[1])\n        self.down2 = Down(self.features[1], self.features[2])\n        self.down3 = Down(self.features[2], self.features[3])\n        # Bottleneck\n        self.bottleneck = DoubleConv(self.features[3], self.features[3])\n        # Attention blocks\n        self.att3 = AttentionBlock(self.features[3], self.features[2], self.features[1])\n        self.att2 = AttentionBlock(self.features[2], self.features[1], self.features[0])\n        self.att1 = AttentionBlock(self.features[1], self.features[0], self.features[0]//2)\n        # Decoder\n        self.up3 = Up(self.features[3] + self.features[2], self.features[2])\n        self.up2 = Up(self.features[2] + self.features[1], self.features[1])\n        self.up1 = Up(self.features[1] + self.features[0], self.features[0])\n        self.outc = nn.Conv2d(self.features[0], n_classes, kernel_size=1)\n        # Prototype layers\n        self.proto_layers = nn.ModuleList([\n            nn.ModuleList([nn.Conv2d(feat, feat, kernel_size=1) for _ in range(num_prototypes)])\n            for feat in self.features\n        ])\n\n    def forward_encoder(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x4 = self.bottleneck(x4)\n        return [x1, x2, x3, x4]\n\n    def compute_prototypes(self, features, mask):\n        all_protos = []\n        for lvl, feat in enumerate(features):\n            lvl_protos = []\n            msk_resized = F.interpolate(mask, size=feat.shape[2:], mode='nearest')\n            for p in range(self.num_prototypes):\n                if p == 0:\n                    proto_mask = msk_resized\n                elif p in [1, 2]:\n                    kernel = torch.ones(3, 3, device=mask.device)\n                    padded = F.pad(msk_resized, (1, 1, 1, 1))\n                    conv = F.conv2d(padded, kernel.view(1, 1, 3, 3))\n                    if p == 1:\n                        proto_mask = ((conv == 1) & (msk_resized == 1)).float()\n                    else:\n                        proto_mask = ((conv >= 3) & (msk_resized == 1)).float()\n                elif p == 3:\n                    eroded = F.max_pool2d(msk_resized, 3, 1, padding=1) < 1\n                    dilated = F.max_pool2d(-msk_resized + 1, 3, 1, padding=1) < 1\n                    proto_mask = (dilated & ~eroded).float()\n                else:\n                    kernel = torch.ones(5, 5, device=mask.device)\n                    padded = F.pad(msk_resized, (2, 2, 2, 2))\n                    thick = F.conv2d(padded, kernel.view(1, 1, 5, 5)) >= 15\n                    proto_mask = (thick.float() * msk_resized)\n                masked = feat * proto_mask\n                sum_mask = proto_mask.sum(dim=(2, 3), keepdim=True) + 1e-8\n                proto = masked.sum(dim=(2, 3), keepdim=True) / sum_mask\n                proto = self.proto_layers[lvl][p](proto)\n                lvl_protos.append(proto)\n            all_protos.append(lvl_protos)\n        return all_protos\n\n    def forward(self, support_img, support_mask, query_img):\n        sup_feats = self.forward_encoder(support_img)\n        qry_feats = self.forward_encoder(query_img)\n        protos = self.compute_prototypes(sup_feats, support_mask)\n        guided = []\n        for lvl, qf in enumerate(qry_feats):\n            guidance = torch.zeros_like(qf)\n            for proto in protos[lvl]:\n                p = proto.mean(0, True).expand_as(qf)\n                guidance += 0.1 * p\n            guided.append(qf + guidance)\n        return self.decode(guided)\n\n    def decode(self, feats):\n        x1, x2, x3, x4 = feats\n        x3_att = self.att3(x4, x3)\n        x = self.up3(x4, x3_att)\n        x2_att = self.att2(x, x2)\n        x = self.up2(x, x2_att)\n        x1_att = self.att1(x, x1)\n        x = self.up1(x, x1_att)\n        return self.outc(x)\n\n# -----------------------------\n# 2. Loss Definition\n# -----------------------------\nclass VesselSegLoss(nn.Module):\n    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n        super(VesselSegLoss, self).__init__()\n        self.alpha, self.beta, self.gamma = alpha, beta, gamma\n\n    def forward(self, pred, target):\n        pred_sig = torch.sigmoid(pred)\n        smooth = 1e-6\n        inter = (pred_sig * target).sum(dim=(2, 3))\n        dice_loss = 1 - ((2 * inter + smooth) / (pred_sig.sum((2, 3)) + target.sum((2, 3)) + smooth))\n        dice_loss = dice_loss.mean()\n        bce_loss = F.binary_cross_entropy_with_logits(pred, target)\n        kernel = torch.ones(1, 1, 3, 3, device=pred.device)\n        dilated_target = F.conv2d(F.pad(target, (1, 1, 1, 1), mode='replicate'), kernel)\n        dilated_target = (dilated_target > 0).float()\n        topology_loss = F.mse_loss(pred_sig, pred_sig * dilated_target)\n        return self.alpha * dice_loss + self.beta * bce_loss + self.gamma * topology_loss, dice_loss, bce_loss, topology_loss\n\n# -----------------------------\n# 3. Visualization Function\n# -----------------------------\ndef visualize_results(sup_img, sup_mask, qry_img, qry_mask, pred_logits, epoch=None):\n    \"\"\"\n    sup_img:  C×H×W  or  1×C×H×W  \n    sup_mask: 1×H×W  or  1×1×H×W  \n    similarly for qry_img, qry_mask; \n    pred_logits: 1×1×H×W logits from your model\n    \"\"\"\n\n    # Squeeze batch dimension if present\n    if sup_img.ndim == 4:  sup_img  = sup_img[0]\n    if sup_mask.ndim == 4: sup_mask = sup_mask[0]\n    if qry_img.ndim == 4:  qry_img  = qry_img[0]\n    if qry_mask.ndim == 4: qry_mask = qry_mask[0]\n    if pred_logits.ndim == 4: pred_logits = pred_logits[0]\n\n    # Move to CPU & numpy\n    sup_img_np   = sup_img.cpu().permute(1, 2, 0).numpy()\n    sup_mask_np  = sup_mask.cpu().squeeze().numpy()\n    qry_img_np   = qry_img.cpu().permute(1, 2, 0).numpy()\n    qry_mask_np  = qry_mask.cpu().squeeze().numpy()\n    pred_np      = torch.sigmoid(pred_logits).cpu().squeeze().numpy()\n\n    # Compute Dice\n    pred_bin = (pred_np > 0.5).astype(np.float32)\n    intersection = (pred_bin * qry_mask_np).sum()\n    dice_score = (2 * intersection) / (pred_bin.sum() + qry_mask_np.sum() + 1e-6)\n\n    # Create overlays\n    sup_overlay = sup_img_np.copy()\n    sup_overlay[sup_mask_np > 0.5] = [1, 0, 0]       # red\n\n    qry_overlay = qry_img_np.copy()\n    qry_overlay[pred_np > 0.5]     = [0, 1, 0]       # green\n\n    # Plot\n    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\n    axs[0, 0].imshow(sup_img_np);      axs[0, 0].set_title(\"Support Image\"); axs[0, 0].axis('off')\n    axs[0, 1].imshow(sup_mask_np, cmap='gray'); axs[0, 1].set_title(\"Support Mask\");  axs[0, 1].axis('off')\n    axs[0, 2].imshow(sup_overlay);     axs[0, 2].set_title(\"Support Overlay\"); axs[0, 2].axis('off')\n\n    axs[1, 0].imshow(qry_img_np);      axs[1, 0].set_title(\"Query Image\");   axs[1, 0].axis('off')\n    axs[1, 1].imshow(qry_mask_np, cmap='gray'); axs[1, 1].set_title(\"Ground Truth\"); axs[1, 1].axis('off')\n    axs[1, 2].imshow(qry_overlay);     axs[1, 2].set_title(f\"Prediction (Dice: {dice_score:.4f})\"); axs[1, 2].axis('off')\n\n    if epoch is not None:\n        fig.suptitle(f\"Epoch {epoch}\", fontsize=16)\n\n    plt.tight_layout()\n    plt.show()\n\n\n# -----------------------------\n# 4. Episodic Dataset & Loader\n# -----------------------------\nclass EpisodicBloodVesselDataset(Dataset):\n    def __init__(self, roots, transform=None, K=3, Q=5, episodes=200):\n        self.paths, self.msks = [], []\n        for root in roots:\n            for cond in ['glaucoma', 'normal']:\n                idr = os.path.join(root, 'images', cond)\n                mdr = os.path.join(root, 'masks', cond)\n                if os.path.isdir(idr) and os.path.isdir(mdr):\n                    for f in os.listdir(idr):\n                        if f.endswith('.png'):\n                            self.paths.append(os.path.join(idr, f))\n                            self.msks.append(os.path.join(mdr, f))\n        self.transform, self.K, self.Q, self.episodes = transform, K, Q, episodes\n\n    def __len__(self):\n        return self.episodes\n\n    def __getitem__(self, idx):\n        idxs = random.sample(range(len(self.paths)), self.K + self.Q)\n        sup_idx, qry_idx = idxs[:self.K], idxs[self.K:]\n        def load_pair(i):\n            img = Image.open(self.paths[i]).convert('RGB')\n            msk = Image.open(self.msks[i]).convert('L')\n            if self.transform:\n                img = self.transform(img)\n                msk = self.transform(msk); msk = (msk > 0.5).float()\n            else:\n                img = transforms.ToTensor()(img)\n                msk = (transforms.ToTensor()(msk) > 0.5).float()\n            return img, msk\n        support = [load_pair(i) for i in sup_idx]\n        query = [load_pair(i) for i in qry_idx]\n        s_i, s_m = zip(*support); q_i, q_m = zip(*query)\n        return torch.stack(s_i), torch.stack(s_m), torch.stack(q_i), torch.stack(q_m)\n\ntransform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\nsupport_path = '/kaggle/input/blood-vessel-support-set-fives/blood_vessel_support_set'\nquery_path   = '/kaggle/input/blood-vessel-query-set/blood_vessel_query_set'\ntrain_ds = EpisodicBloodVesselDataset([support_path, query_path], transform, 3, 5, 200)\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)\n\n# -----------------------------\n# 5. Meta-Training Loop\n# -----------------------------\nimport matplotlib.pyplot as plt\n\ndef train_few_shot(model, criterion, optimizer, scheduler, loader, device, epochs=20):\n    scaler = torch.amp.GradScaler(\"cuda\")\n    \n\n    # For consistent visualization\n    data_iter = iter(loader)\n    viz_si, viz_sm, viz_qi, viz_qm = next(data_iter)\n\n    loss_values = []\n\n    for ep in range(1, epochs + 1):\n        model.train()\n        total_loss = 0.0\n        loop = tqdm(loader, desc=f'Epoch {ep}/{epochs}', leave=False)\n\n        for s_i, s_m, q_i, q_m in loop:\n            s_i = s_i.squeeze(0).to(device, memory_format=torch.channels_last)\n            s_m = s_m.squeeze(0).to(device)\n            q_i = q_i.squeeze(0).to(device, memory_format=torch.channels_last)\n            q_m = q_m.squeeze(0).to(device)\n\n            optimizer.zero_grad()\n\n            with torch.amp.autocast(\"cuda\"):\n                pred = model(s_i, s_m, q_i)\n                loss, _, _, _ = criterion(pred, q_m)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            total_loss += loss.item()\n            loop.set_postfix(loss=total_loss / (loop.n + 1))\n\n        avg_loss = total_loss / len(loader)\n        loss_values.append(avg_loss)\n        scheduler.step()\n        print(f\"Epoch {ep}: Loss={avg_loss:.4f}\")\n\n        # Visualization every 5 epochs\n        if ep % 5 == 0 or ep==1:\n            model.eval()\n            with torch.no_grad():\n                pred_v = model(\n                    viz_si.squeeze(0).to(device, memory_format=torch.channels_last),\n                    viz_sm.squeeze(0).to(device),\n                    viz_qi.squeeze(0).to(device, memory_format=torch.channels_last)\n                )\n                # Instead of squeezing, use indexing to get the first element\n            visualize_results(\n                viz_si[0], viz_sm[0],\n                viz_qi[0], viz_qm[0],\n                pred_v[0] if pred_v.dim() > 3 else pred_v,\n                epoch=ep\n            )\n\n            model.train()\n\n        # Save model checkpoint every 10 epochs\n        if ep % 10 == 0:\n            ckpt_path = f\"checkpoint_epoch_{ep}.pth\"\n            torch.save(model.state_dict(), ckpt_path)\n            print(f\"Saved checkpoint at {ckpt_path}\")\n\n    # Plot loss vs epoch after training\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(1, epochs + 1), loss_values, marker='o')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss over Epochs')\n    plt.grid(True)\n    plt.show()\n\n    return model\n\n# -----------------------------\n# 6. Initialize & Run\n# -----------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ProtoUNet(3, 1, 5).to(device)\ncriterion = VesselSegLoss(0.5, 0.3, 0.2)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300, eta_min=1e-6)\nmodel = train_few_shot(model, criterion, optimizer, scheduler, train_loader, device, epochs=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T11:52:01.907546Z","iopub.execute_input":"2025-04-22T11:52:01.907974Z","iopub.status.idle":"2025-04-22T12:55:55.152199Z","shell.execute_reply.started":"2025-04-22T11:52:01.907942Z","shell.execute_reply":"2025-04-22T12:55:55.151521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n# Ensure ProtoUNet and visualize_results are defined/imported above\n\nclass RetinalVesselEpisodicDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None, K=3, Q=5, episodes=20):\n        self.image_paths, self.mask_paths = [], []\n        for fn in os.listdir(image_dir):\n            if fn.lower().endswith(('.png', '.jpg', '.jpeg')):\n                img_path = os.path.join(image_dir, fn)\n                mask_path = os.path.join(mask_dir, fn)\n                if os.path.isfile(mask_path):\n                    self.image_paths.append(img_path)\n                    self.mask_paths.append(mask_path)\n        assert len(self.image_paths) >= K + Q, (\n            f\"Not enough samples ({len(self.image_paths)}) for K={K}+Q={Q}\"\n        )\n        self.transform = transform\n        self.K = K\n        self.Q = Q\n        self.episodes = episodes\n\n    def __len__(self):\n        return self.episodes\n\n    def __getitem__(self, idx):\n        total = len(self.image_paths)\n        chosen = random.sample(range(total), self.K + self.Q)\n        sup_idxs, qry_idxs = chosen[:self.K], chosen[self.K:]\n\n        def load_pair(i):\n            img = Image.open(self.image_paths[i]).convert('RGB')\n            msk = Image.open(self.mask_paths[i]).convert('L')\n            if self.transform:\n                img = self.transform(img)\n                msk = (self.transform(msk) > 0.5).float()\n            else:\n                img = transforms.ToTensor()(img)\n                msk = (transforms.ToTensor()(msk) > 0.5).float()\n            return img, msk\n\n        support = [load_pair(i) for i in sup_idxs]\n        query   = [load_pair(i) for i in qry_idxs]\n\n        s_imgs, s_msks = zip(*support)\n        q_imgs, q_msks = zip(*query)\n        return torch.stack(s_imgs), torch.stack(s_msks), torch.stack(q_imgs), torch.stack(q_msks)\n\n# Configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\nimage_dir = '/kaggle/input/retina-blood-vessel/Data/train/image'\nmask_dir  = '/kaggle/input/retina-blood-vessel/Data/train/mask'\n\n# Dataset and DataLoader\ntest_ds = RetinalVesselEpisodicDataset(image_dir, mask_dir, transform, K=3, Q=5, episodes=20)\ntest_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n\n# Load model and checkpoint\nmodel = ProtoUNet(n_channels=3, n_classes=1, num_prototypes=5).to(device)\ncheckpoint = torch.load('/kaggle/working/checkpoint_epoch_10.pth', map_location=device)\nmodel.load_state_dict(checkpoint)\nmodel.eval()\n\n# Metrics aggregation\ntotal_cm = np.zeros((2, 2), dtype=np.int64)\n\n# Few-shot testing loop\nwith torch.no_grad():\n    for idx, (s_imgs, s_msks, q_imgs, q_msks) in enumerate(test_loader, start=1):\n        # Remove batch dim and move to device\n        s_imgs, s_msks = s_imgs[0].to(device), s_msks[0].to(device)\n        q_imgs, q_msks = q_imgs[0].to(device), q_msks[0].to(device)\n\n        # Forward pass\n        pred = model(s_imgs, s_msks, q_imgs)\n        pred_bin = (pred > 0.5).float()\n\n        # Update confusion matrix\n        y_true = q_msks.view(-1).cpu().numpy().astype(int)\n        y_pred = pred_bin.view(-1).cpu().numpy().astype(int)\n        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n        total_cm += cm\n\n        # Visualization\n        visualize_results(s_imgs, s_msks, q_imgs, q_msks, pred, epoch=f\"Test_{idx}\")\n        if idx >= test_ds.episodes:\n            break\n\n# Compute per-class IoU and Dice\nmetrics = {}\nfor cls in [0, 1]:\n    tp = total_cm[cls, cls]\n    fn = total_cm[cls, 1 - cls]\n    fp = total_cm[1 - cls, cls]\n    if cls == 0:\n        # Background: treated as true negatives for class 0\n        tn = tp  # here tp is tn\n        fn_bg = fn\n        fp_bg = fp\n        iou = tn / (tn + fn_bg + fp_bg + 1e-8)\n        dice = 2 * tn / (2 * tn + fn_bg + fp_bg + 1e-8)\n    else:\n        iou = tp / (tp + fn + fp + 1e-8)\n        dice = 2 * tp / (2 * tp + fn + fp + 1e-8)\n    metrics[f'class_{cls}'] = {'iou': iou, 'dice': dice}\n\n# Print metrics\nprint(\"Mean IoU per class:\")\nprint(f\"  Class 0 (Background): {metrics['class_0']['iou']:.4f}\")\nprint(f\"  Class 1 (Vessel):      {metrics['class_1']['iou']:.4f}\")\nprint(\"Mean Dice per class:\")\nprint(f\"  Class 0 (Background): {metrics['class_0']['dice']:.4f}\")\nprint(f\"  Class 1 (Vessel):      {metrics['class_1']['dice']:.4f}\")\n\n# Plot aggregated confusion matrix\nfig, ax = plt.subplots()\nim = ax.imshow(total_cm, interpolation='nearest')\nax.set_title('Aggregated Confusion Matrix')\nax.set_xlabel('Predicted Label')\nax.set_ylabel('True Label')\nax.set_xticks([0, 1])\nax.set_yticks([0, 1])\nax.set_xticklabels(['Background', 'Vessel'])\nax.set_yticklabels(['Background', 'Vessel'])\nfor i in range(total_cm.shape[0]):\n    for j in range(total_cm.shape[1]):\n        ax.text(j, i, total_cm[i, j], ha=\"center\", va=\"center\")\nfig.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T13:05:24.456657Z","iopub.execute_input":"2025-04-22T13:05:24.456991Z","iopub.status.idle":"2025-04-22T13:05:45.217576Z","shell.execute_reply.started":"2025-04-22T13:05:24.456964Z","shell.execute_reply":"2025-04-22T13:05:45.216781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}